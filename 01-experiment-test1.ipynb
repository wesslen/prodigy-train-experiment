{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "627ee331-9138-41cf-9dff-0afb5e6c8104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;1m✘ Can't find 'news' in database SQLite\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[38;5;1m✘ Can't find 'news_train' in database SQLite\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[38;5;1m✘ Can't find 'news_eval' in database SQLite\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m prodigy drop news\n",
    "!python -m prodigy drop news_train\n",
    "!python -m prodigy drop news_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a031ec96-4d9d-4d8a-8da6-6a66683d96f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created dataset 'news' in database SQLite\u001b[0m\n",
      "\u001b[38;5;2m✔ Imported 373 annotations to 'news' (session 2023-05-02_11-35-52) in\n",
      "database SQLite\u001b[0m\n",
      "Found and keeping existing \"answer\" in 373 examples\n"
     ]
    }
   ],
   "source": [
    "!python -m prodigy db-in news annotated_news_headlines.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2183c606-25cf-4db0-840c-a3555282afac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "========================= Generating Prodigy config =========================\u001b[0m\n",
      "\u001b[38;5;4mℹ Auto-generating config with spaCy\u001b[0m\n",
      "\u001b[38;5;2m✔ Generated training config\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-05-02 11:35:53,300] [INFO] Set up nlp object from config\n",
      "Components: ner\n",
      "Merging training and evaluation data for 1 components\n",
      "  - [ner] Training: 298 | Evaluation: 74 (20% split)\n",
      "Training: 298 | Evaluation: 74\n",
      "Labels: ner (4)\n",
      "[2023-05-02 11:35:53,319] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2023-05-02 11:35:53,321] [INFO] Created vocabulary\n",
      "[2023-05-02 11:35:53,321] [INFO] Finished initializing nlp object\n",
      "[2023-05-02 11:35:53,485] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "Components: ner\n",
      "Merging training and evaluation data for 1 components\n",
      "  - [ner] Training: 298 | Evaluation: 74 (20% split)\n",
      "Training: 298 | Evaluation: 74\n",
      "Labels: ner (4)\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     56.00    0.00    0.00    0.00    0.00\n",
      "  7     200         72.28   1779.84   68.04   84.62   56.90    0.68\n",
      " 17     400         20.24     53.48   69.23   78.26   62.07    0.69\n",
      " 28     600          2.99      1.52   69.90   80.00   62.07    0.70\n",
      " 42     800          2.23      1.97   72.00   85.71   62.07    0.72\n",
      " 60    1000         11.23      5.81   72.73   87.80   62.07    0.73\n",
      " 81    1200         44.52     18.26   73.27   86.05   63.79    0.73\n",
      "106    1400        103.79     29.36   68.63   79.55   60.34    0.69\n",
      "138    1600        120.49     30.78   68.69   82.93   58.62    0.69\n",
      "175    1800         55.98     22.38   68.69   82.93   58.62    0.69\n",
      "222    2000         18.79      2.82   69.39   85.00   58.62    0.69\n",
      "276    2200         11.13      2.03   69.39   85.00   58.62    0.69\n",
      "343    2400         35.45      8.18   70.83   89.47   58.62    0.71\n",
      "410    2600          0.65      0.23   70.10   87.18   58.62    0.70\n",
      "476    2800          4.77      1.26   69.39   85.00   58.62    0.69\n"
     ]
    }
   ],
   "source": [
    "!python -m prodigy train --ner news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5912f-c670-4814-a0e6-a2939525c880",
   "metadata": {},
   "source": [
    "ℹ Using CPU\n",
    "\n",
    "========================= Generating Prodigy config =========================\n",
    "ℹ Auto-generating config with spaCy\n",
    "✔ Generated training config\n",
    "\n",
    "=========================== Initializing pipeline ===========================\n",
    "[2023-05-02 14:56:44,408] [INFO] Set up nlp object from config\n",
    "Components: ner\n",
    "Merging training and evaluation data for 1 components\n",
    "  - [ner] Training: 298 | Evaluation: 74 (20% split)\n",
    "Training: 298 | Evaluation: 74\n",
    "Labels: ner (4)\n",
    "[2023-05-02 14:56:44,459] [INFO] Pipeline: ['tok2vec', 'ner']\n",
    "[2023-05-02 14:56:44,463] [INFO] Created vocabulary\n",
    "[2023-05-02 14:56:44,464] [INFO] Finished initializing nlp object\n",
    "[2023-05-02 14:56:44,706] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
    "✔ Initialized pipeline\n",
    "\n",
    "============================= Training pipeline =============================\n",
    "Components: ner\n",
    "Merging training and evaluation data for 1 components\n",
    "  - [ner] Training: 298 | Evaluation: 74 (20% split)\n",
    "Training: 298 | Evaluation: 74\n",
    "Labels: ner (4)\n",
    "ℹ Pipeline: ['tok2vec', 'ner']\n",
    "ℹ Initial learn rate: 0.001\n",
    "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
    "---  ------  ------------  --------  ------  ------  ------  ------\n",
    "  0       0          0.00     56.00    0.00    0.00    0.00    0.00\n",
    "  7     200         70.53   1779.85   69.47   89.19   56.90    0.69\n",
    " 17     400         17.79     54.66   74.00   88.10   63.79    0.74\n",
    " 28     600          4.55      4.05   70.71   85.37   60.34    0.71\n",
    " 42     800          4.28      2.71   74.51   86.36   65.52    0.75\n",
    " 60    1000          0.09      0.04   73.08   82.61   65.52    0.73\n",
    " 81    1200          4.32      1.62   72.16   89.74   60.34    0.72\n",
    "106    1400         43.62     13.44   75.25   88.37   65.52    0.75\n",
    "138    1600         66.88     27.63   70.97   94.29   56.90    0.71\n",
    "175    1800         34.79      7.93   72.34   94.44   58.62    0.72\n",
    "222    2000        184.67     43.45   70.21   91.67   56.90    0.70\n",
    "276    2200         34.44     12.67   70.21   91.67   56.90    0.70\n",
    "343    2400          5.49      0.61   71.58   91.89   58.62    0.72\n",
    "410    2600         56.66     11.28   70.21   91.67   56.90    0.70\n",
    "476    2800         51.57     10.86   66.67   88.57   53.45    0.67\n",
    "543    3000         70.47      6.02   68.75   86.84   56.90    0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8647056-36ab-474e-92b7-01e8e8f3726b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created dataset 'news_train' in database SQLite\u001b[0m\n",
      "\u001b[38;5;2m✔ Imported 273 annotations to 'news_train' (session\n",
      "2023-05-02_11-40-37) in database SQLite\u001b[0m\n",
      "Found and keeping existing \"answer\" in 273 examples\n"
     ]
    }
   ],
   "source": [
    "!python -m prodigy db-in news_train train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82bd0be4-b2d5-42bf-a4bd-a06d6b98c6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created dataset 'news_eval' in database SQLite\u001b[0m\r\n",
      "\u001b[38;5;2m✔ Imported 100 annotations to 'news_eval' (session 2023-05-02_11-40-38)\r\n",
      "in database SQLite\u001b[0m\r\n",
      "Found and keeping existing \"answer\" in 100 examples\r\n"
     ]
    }
   ],
   "source": [
    "!python -m prodigy db-in news_eval eval.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ae55bb-be12-466c-b6a5-45b499cee02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "========================= Generating Prodigy config =========================\u001b[0m\n",
      "\u001b[38;5;4mℹ Auto-generating config with spaCy\u001b[0m\n",
      "\u001b[38;5;2m✔ Generated training config\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-05-02 11:40:39,673] [INFO] Set up nlp object from config\n",
      "Components: ner\n",
      "Merging training and evaluation data for 1 components\n",
      "  - [ner] Training: 273 | Evaluation: 99 (from datasets)\n",
      "Training: 273 | Evaluation: 99\n",
      "Labels: ner (4)\n",
      "[2023-05-02 11:40:39,692] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2023-05-02 11:40:39,694] [INFO] Created vocabulary\n",
      "[2023-05-02 11:40:39,694] [INFO] Finished initializing nlp object\n",
      "[2023-05-02 11:40:39,843] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "Components: ner\n",
      "Merging training and evaluation data for 1 components\n",
      "  - [ner] Training: 273 | Evaluation: 99 (from datasets)\n",
      "Training: 273 | Evaluation: 99\n",
      "Labels: ner (4)\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     56.11    0.00    0.00    0.00    0.00\n",
      "  8     200         69.25   1727.74   37.04   50.00   29.41    0.37\n",
      " 19     400         47.84     82.08   41.67   71.43   29.41    0.42\n",
      " 31     600          0.45      0.52   41.67   71.43   29.41    0.42\n",
      " 47     800          0.02      0.02   40.00   56.76   30.88    0.40\n",
      " 66    1000         14.69      6.78   40.00   62.50   29.41    0.40\n",
      " 89    1200          2.39      1.08   41.67   71.43   29.41    0.42\n",
      "118    1400         42.54     17.30   36.36   47.62   29.41    0.36\n",
      "152    1600         94.10     22.74   37.50   64.29   26.47    0.37\n",
      "193    1800         25.83      9.31   43.48   83.33   29.41    0.43\n",
      "243    2000         29.35      7.42   41.30   79.17   27.94    0.41\n",
      "306    2200        341.98     49.46   43.75   75.00   30.88    0.44\n",
      "373    2400         38.16     10.66   43.01   80.00   29.41    0.43\n",
      "440    2600         76.85      8.11   40.86   76.00   27.94    0.41\n",
      "506    2800          0.08      0.03   39.18   65.52   27.94    0.39\n",
      "573    3000        137.48     17.19   46.46   74.19   33.82    0.46\n",
      "640    3200         25.54      6.51   42.55   76.92   29.41    0.43\n",
      "706    3400        200.39     17.46   40.43   73.08   27.94    0.40\n",
      "773    3600        112.91      9.84   43.01   80.00   29.41    0.43\n",
      "840    3800         53.13      9.88   40.40   64.52   29.41    0.40\n",
      "906    4000        177.31     28.01   43.75   75.00   30.88    0.44\n",
      "973    4200         19.87      3.68   42.55   76.92   29.41    0.43\n",
      "1040    4400         72.16      8.26   38.46   55.56   29.41    0.38\n",
      "1106    4600        218.57     15.83   39.22   58.82   29.41    0.39\n"
     ]
    }
   ],
   "source": [
    "!python -m prodigy train --ner news_train,eval:news_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf9b626-c4ff-40b2-b6a0-633d9835b5bd",
   "metadata": {},
   "source": [
    "ℹ Using CPU\n",
    "\n",
    "========================= Generating Prodigy config =========================\n",
    "ℹ Auto-generating config with spaCy\n",
    "✔ Generated training config\n",
    "\n",
    "=========================== Initializing pipeline ===========================\n",
    "[2023-05-02 15:04:48,073] [INFO] Set up nlp object from config\n",
    "Components: ner\n",
    "Merging training and evaluation data for 1 components\n",
    "  - [ner] Training: 273 | Evaluation: 99 (from datasets)\n",
    "Training: 273 | Evaluation: 99\n",
    "Labels: ner (4)\n",
    "[2023-05-02 15:04:48,125] [INFO] Pipeline: ['tok2vec', 'ner']\n",
    "[2023-05-02 15:04:48,129] [INFO] Created vocabulary\n",
    "[2023-05-02 15:04:48,130] [INFO] Finished initializing nlp object\n",
    "[2023-05-02 15:04:48,357] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
    "✔ Initialized pipeline\n",
    "\n",
    "============================= Training pipeline =============================\n",
    "Components: ner\n",
    "Merging training and evaluation data for 1 components\n",
    "  - [ner] Training: 273 | Evaluation: 99 (from datasets)\n",
    "Training: 273 | Evaluation: 99\n",
    "Labels: ner (4)\n",
    "ℹ Pipeline: ['tok2vec', 'ner']\n",
    "ℹ Initial learn rate: 0.001\n",
    "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
    "---  ------  ------------  --------  ------  ------  ------  ------\n",
    "  0       0          0.00     56.11    0.00    0.00    0.00    0.00\n",
    "  8     200         67.68   1706.38   35.05   58.62   25.00    0.35\n",
    " 19     400         48.75     96.31   42.11   74.07   29.41    0.42\n",
    " 31     600          4.30      7.75   43.14   64.71   32.35    0.43\n",
    " 47     800          0.20      0.09   40.40   64.52   29.41    0.40\n",
    " 66    1000         21.49      7.34   38.00   59.38   27.94    0.38\n",
    " 89    1200          0.85      0.48   36.89   54.29   27.94    0.37\n",
    "118    1400         25.89      9.57   33.33   45.00   26.47    0.33\n",
    "152    1600        118.67     50.31   37.50   64.29   26.47    0.37\n",
    "193    1800         45.59     14.22   38.00   59.38   27.94    0.38\n",
    "243    2000         14.89      4.81   36.04   46.51   29.41    0.36\n",
    "306    2200         19.05      3.07   46.02   57.78   38.24    0.46\n",
    "373    2400         24.70      3.84   42.59   57.50   33.82    0.43\n",
    "440    2600         69.18     10.95   40.82   66.67   29.41    0.41\n",
    "506    2800        155.87     20.43   36.54   52.78   27.94    0.37\n",
    "573    3000          6.48      1.67   39.18   65.52   27.94    0.39\n",
    "640    3200        237.26     31.02   36.96   70.83   25.00    0.37\n",
    "706    3400        198.38     29.66   48.54   71.43   36.76    0.49\n",
    "773    3600          0.00      0.00   48.08   69.44   36.76    0.48\n",
    "840    3800         38.16      4.01   44.90   73.33   32.35    0.45\n",
    "906    4000          0.00      0.00   44.44   70.97   32.35    0.44\n",
    "973    4200         14.14      1.37   40.35   50.00   33.82    0.40\n",
    "1040    4400          1.39      0.14   42.42   67.74   30.88    0.42\n",
    "1106    4600        480.32     58.45   44.68   80.77   30.88    0.45\n",
    "1173    4800          6.54      0.70   43.96   86.96   29.41    0.44\n",
    "1240    5000        106.19      8.15   44.44   90.91   29.41    0.44"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
