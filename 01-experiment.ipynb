{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "627ee331-9138-41cf-9dff-0afb5e6c8104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;2m✔ Removed 'news' from database SQLite\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[38;5;1m✘ Can't find 'news_train' in database SQLite\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[38;5;1m✘ Can't find 'news_eval' in database SQLite\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m prodigy drop news\n",
    "!python -m prodigy drop news_train\n",
    "!python -m prodigy drop news_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a031ec96-4d9d-4d8a-8da6-6a66683d96f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created dataset 'news' in database SQLite\u001b[0m\n",
      "\u001b[38;5;2m✔ Imported 373 annotations to 'news' (session 2023-05-02_14-56-33) in\n",
      "database SQLite\u001b[0m\n",
      "Found and keeping existing \"answer\" in 373 examples\n"
     ]
    }
   ],
   "source": [
    "!python -m prodigy db-in news annotated_news_headlines.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2183c606-25cf-4db0-840c-a3555282afac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "========================= Generating Prodigy config =========================\u001b[0m\n",
      "\u001b[38;5;4mℹ Auto-generating config with spaCy\u001b[0m\n",
      "\u001b[38;5;2m✔ Generated training config\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-05-02 14:56:44,408] [INFO] Set up nlp object from config\n",
      "Components: ner\n",
      "Merging training and evaluation data for 1 components\n",
      "  - [ner] Training: 298 | Evaluation: 74 (20% split)\n",
      "Training: 298 | Evaluation: 74\n",
      "Labels: ner (4)\n",
      "[2023-05-02 14:56:44,459] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2023-05-02 14:56:44,463] [INFO] Created vocabulary\n",
      "[2023-05-02 14:56:44,464] [INFO] Finished initializing nlp object\n",
      "[2023-05-02 14:56:44,706] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "Components: ner\n",
      "Merging training and evaluation data for 1 components\n",
      "  - [ner] Training: 298 | Evaluation: 74 (20% split)\n",
      "Training: 298 | Evaluation: 74\n",
      "Labels: ner (4)\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     56.00    0.00    0.00    0.00    0.00\n",
      "  7     200         70.53   1779.85   69.47   89.19   56.90    0.69\n",
      " 17     400         17.79     54.66   74.00   88.10   63.79    0.74\n",
      " 28     600          4.55      4.05   70.71   85.37   60.34    0.71\n",
      " 42     800          4.28      2.71   74.51   86.36   65.52    0.75\n",
      " 60    1000          0.09      0.04   73.08   82.61   65.52    0.73\n",
      " 81    1200          4.32      1.62   72.16   89.74   60.34    0.72\n",
      "106    1400         43.62     13.44   75.25   88.37   65.52    0.75\n",
      "138    1600         66.88     27.63   70.97   94.29   56.90    0.71\n",
      "175    1800         34.79      7.93   72.34   94.44   58.62    0.72\n",
      "222    2000        184.67     43.45   70.21   91.67   56.90    0.70\n",
      "276    2200         34.44     12.67   70.21   91.67   56.90    0.70\n",
      "343    2400          5.49      0.61   71.58   91.89   58.62    0.72\n",
      "410    2600         56.66     11.28   70.21   91.67   56.90    0.70\n",
      "476    2800         51.57     10.86   66.67   88.57   53.45    0.67\n",
      "543    3000         70.47      6.02   68.75   86.84   56.90    0.69\n"
     ]
    }
   ],
   "source": [
    "!python -m prodigy train --ner news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5912f-c670-4814-a0e6-a2939525c880",
   "metadata": {},
   "source": [
    "ℹ Using CPU\n",
    "\n",
    "========================= Generating Prodigy config =========================\n",
    "ℹ Auto-generating config with spaCy\n",
    "✔ Generated training config\n",
    "\n",
    "=========================== Initializing pipeline ===========================\n",
    "[2023-05-02 14:56:44,408] [INFO] Set up nlp object from config\n",
    "Components: ner\n",
    "Merging training and evaluation data for 1 components\n",
    "  - [ner] Training: 298 | Evaluation: 74 (20% split)\n",
    "Training: 298 | Evaluation: 74\n",
    "Labels: ner (4)\n",
    "[2023-05-02 14:56:44,459] [INFO] Pipeline: ['tok2vec', 'ner']\n",
    "[2023-05-02 14:56:44,463] [INFO] Created vocabulary\n",
    "[2023-05-02 14:56:44,464] [INFO] Finished initializing nlp object\n",
    "[2023-05-02 14:56:44,706] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
    "✔ Initialized pipeline\n",
    "\n",
    "============================= Training pipeline =============================\n",
    "Components: ner\n",
    "Merging training and evaluation data for 1 components\n",
    "  - [ner] Training: 298 | Evaluation: 74 (20% split)\n",
    "Training: 298 | Evaluation: 74\n",
    "Labels: ner (4)\n",
    "ℹ Pipeline: ['tok2vec', 'ner']\n",
    "ℹ Initial learn rate: 0.001\n",
    "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
    "---  ------  ------------  --------  ------  ------  ------  ------\n",
    "  0       0          0.00     56.00    0.00    0.00    0.00    0.00\n",
    "  7     200         70.53   1779.85   69.47   89.19   56.90    0.69\n",
    " 17     400         17.79     54.66   74.00   88.10   63.79    0.74\n",
    " 28     600          4.55      4.05   70.71   85.37   60.34    0.71\n",
    " 42     800          4.28      2.71   74.51   86.36   65.52    0.75\n",
    " 60    1000          0.09      0.04   73.08   82.61   65.52    0.73\n",
    " 81    1200          4.32      1.62   72.16   89.74   60.34    0.72\n",
    "106    1400         43.62     13.44   75.25   88.37   65.52    0.75\n",
    "138    1600         66.88     27.63   70.97   94.29   56.90    0.71\n",
    "175    1800         34.79      7.93   72.34   94.44   58.62    0.72\n",
    "222    2000        184.67     43.45   70.21   91.67   56.90    0.70\n",
    "276    2200         34.44     12.67   70.21   91.67   56.90    0.70\n",
    "343    2400          5.49      0.61   71.58   91.89   58.62    0.72\n",
    "410    2600         56.66     11.28   70.21   91.67   56.90    0.70\n",
    "476    2800         51.57     10.86   66.67   88.57   53.45    0.67\n",
    "543    3000         70.47      6.02   68.75   86.84   56.90    0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8647056-36ab-474e-92b7-01e8e8f3726b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created dataset 'news_train' in database SQLite\u001b[0m\n",
      "\u001b[38;5;2m✔ Imported 273 annotations to 'news_train' (session\n",
      "2023-05-02_15-00-49) in database SQLite\u001b[0m\n",
      "Found and keeping existing \"answer\" in 273 examples\n"
     ]
    }
   ],
   "source": [
    "!python -m prodigy db-in news_train train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82bd0be4-b2d5-42bf-a4bd-a06d6b98c6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Imported 100 annotations to 'news_eval' (session 2023-05-02_15-04-42)\n",
      "in database SQLite\u001b[0m\n",
      "Found and keeping existing \"answer\" in 100 examples\n"
     ]
    }
   ],
   "source": [
    "!python -m prodigy db-in news_eval eval.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5ae55bb-be12-466c-b6a5-45b499cee02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "========================= Generating Prodigy config =========================\u001b[0m\n",
      "\u001b[38;5;4mℹ Auto-generating config with spaCy\u001b[0m\n",
      "\u001b[38;5;2m✔ Generated training config\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-05-02 15:04:48,073] [INFO] Set up nlp object from config\n",
      "Components: ner\n",
      "Merging training and evaluation data for 1 components\n",
      "  - [ner] Training: 273 | Evaluation: 99 (from datasets)\n",
      "Training: 273 | Evaluation: 99\n",
      "Labels: ner (4)\n",
      "[2023-05-02 15:04:48,125] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2023-05-02 15:04:48,129] [INFO] Created vocabulary\n",
      "[2023-05-02 15:04:48,130] [INFO] Finished initializing nlp object\n",
      "[2023-05-02 15:04:48,357] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "Components: ner\n",
      "Merging training and evaluation data for 1 components\n",
      "  - [ner] Training: 273 | Evaluation: 99 (from datasets)\n",
      "Training: 273 | Evaluation: 99\n",
      "Labels: ner (4)\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     56.11    0.00    0.00    0.00    0.00\n",
      "  8     200         67.68   1706.38   35.05   58.62   25.00    0.35\n",
      " 19     400         48.75     96.31   42.11   74.07   29.41    0.42\n",
      " 31     600          4.30      7.75   43.14   64.71   32.35    0.43\n",
      " 47     800          0.20      0.09   40.40   64.52   29.41    0.40\n",
      " 66    1000         21.49      7.34   38.00   59.38   27.94    0.38\n",
      " 89    1200          0.85      0.48   36.89   54.29   27.94    0.37\n",
      "118    1400         25.89      9.57   33.33   45.00   26.47    0.33\n",
      "152    1600        118.67     50.31   37.50   64.29   26.47    0.37\n",
      "193    1800         45.59     14.22   38.00   59.38   27.94    0.38\n",
      "243    2000         14.89      4.81   36.04   46.51   29.41    0.36\n",
      "306    2200         19.05      3.07   46.02   57.78   38.24    0.46\n",
      "373    2400         24.70      3.84   42.59   57.50   33.82    0.43\n",
      "440    2600         69.18     10.95   40.82   66.67   29.41    0.41\n",
      "506    2800        155.87     20.43   36.54   52.78   27.94    0.37\n",
      "573    3000          6.48      1.67   39.18   65.52   27.94    0.39\n",
      "640    3200        237.26     31.02   36.96   70.83   25.00    0.37\n",
      "706    3400        198.38     29.66   48.54   71.43   36.76    0.49\n",
      "773    3600          0.00      0.00   48.08   69.44   36.76    0.48\n",
      "840    3800         38.16      4.01   44.90   73.33   32.35    0.45\n",
      "906    4000          0.00      0.00   44.44   70.97   32.35    0.44\n",
      "973    4200         14.14      1.37   40.35   50.00   33.82    0.40\n",
      "1040    4400          1.39      0.14   42.42   67.74   30.88    0.42\n",
      "1106    4600        480.32     58.45   44.68   80.77   30.88    0.45\n",
      "1173    4800          6.54      0.70   43.96   86.96   29.41    0.44\n",
      "1240    5000        106.19      8.15   44.44   90.91   29.41    0.44\n"
     ]
    }
   ],
   "source": [
    "!python -m prodigy train --ner news_train,eval:news_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf9b626-c4ff-40b2-b6a0-633d9835b5bd",
   "metadata": {},
   "source": [
    "ℹ Using CPU\n",
    "\n",
    "========================= Generating Prodigy config =========================\n",
    "ℹ Auto-generating config with spaCy\n",
    "✔ Generated training config\n",
    "\n",
    "=========================== Initializing pipeline ===========================\n",
    "[2023-05-02 15:04:48,073] [INFO] Set up nlp object from config\n",
    "Components: ner\n",
    "Merging training and evaluation data for 1 components\n",
    "  - [ner] Training: 273 | Evaluation: 99 (from datasets)\n",
    "Training: 273 | Evaluation: 99\n",
    "Labels: ner (4)\n",
    "[2023-05-02 15:04:48,125] [INFO] Pipeline: ['tok2vec', 'ner']\n",
    "[2023-05-02 15:04:48,129] [INFO] Created vocabulary\n",
    "[2023-05-02 15:04:48,130] [INFO] Finished initializing nlp object\n",
    "[2023-05-02 15:04:48,357] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
    "✔ Initialized pipeline\n",
    "\n",
    "============================= Training pipeline =============================\n",
    "Components: ner\n",
    "Merging training and evaluation data for 1 components\n",
    "  - [ner] Training: 273 | Evaluation: 99 (from datasets)\n",
    "Training: 273 | Evaluation: 99\n",
    "Labels: ner (4)\n",
    "ℹ Pipeline: ['tok2vec', 'ner']\n",
    "ℹ Initial learn rate: 0.001\n",
    "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
    "---  ------  ------------  --------  ------  ------  ------  ------\n",
    "  0       0          0.00     56.11    0.00    0.00    0.00    0.00\n",
    "  8     200         67.68   1706.38   35.05   58.62   25.00    0.35\n",
    " 19     400         48.75     96.31   42.11   74.07   29.41    0.42\n",
    " 31     600          4.30      7.75   43.14   64.71   32.35    0.43\n",
    " 47     800          0.20      0.09   40.40   64.52   29.41    0.40\n",
    " 66    1000         21.49      7.34   38.00   59.38   27.94    0.38\n",
    " 89    1200          0.85      0.48   36.89   54.29   27.94    0.37\n",
    "118    1400         25.89      9.57   33.33   45.00   26.47    0.33\n",
    "152    1600        118.67     50.31   37.50   64.29   26.47    0.37\n",
    "193    1800         45.59     14.22   38.00   59.38   27.94    0.38\n",
    "243    2000         14.89      4.81   36.04   46.51   29.41    0.36\n",
    "306    2200         19.05      3.07   46.02   57.78   38.24    0.46\n",
    "373    2400         24.70      3.84   42.59   57.50   33.82    0.43\n",
    "440    2600         69.18     10.95   40.82   66.67   29.41    0.41\n",
    "506    2800        155.87     20.43   36.54   52.78   27.94    0.37\n",
    "573    3000          6.48      1.67   39.18   65.52   27.94    0.39\n",
    "640    3200        237.26     31.02   36.96   70.83   25.00    0.37\n",
    "706    3400        198.38     29.66   48.54   71.43   36.76    0.49\n",
    "773    3600          0.00      0.00   48.08   69.44   36.76    0.48\n",
    "840    3800         38.16      4.01   44.90   73.33   32.35    0.45\n",
    "906    4000          0.00      0.00   44.44   70.97   32.35    0.44\n",
    "973    4200         14.14      1.37   40.35   50.00   33.82    0.40\n",
    "1040    4400          1.39      0.14   42.42   67.74   30.88    0.42\n",
    "1106    4600        480.32     58.45   44.68   80.77   30.88    0.45\n",
    "1173    4800          6.54      0.70   43.96   86.96   29.41    0.44\n",
    "1240    5000        106.19      8.15   44.44   90.91   29.41    0.44"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
